# ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…Ù„Ù Ø£Ø¶Ù:

import logging
logger = logging.getLogger(__name__)

class TrendsFetcher:
    def __init__(self):
        # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ mock data
        self.mock_enabled = False  # âŒ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ù†Ù…Ø§Ù…Ø§Ù‹
        logger.info("ğŸ”¥ TrendsFetcher initialized - REAL DATA ONLY")
    
    def get_trending_keywords(self, keyword, timeframe='today 3-m'):
        """Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙÙ‚Ø·"""
        
        logger.info(f"ğŸ“¡ Fetching REAL Google Trends for: {keyword}")
        
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Google Trends Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
            from pytrends.request import TrendReq
            
            pytrends = TrendReq(hl='en-US', tz=360)
            pytrends.build_payload([keyword], cat=0, timeframe=timeframe, geo='', gprop='')
            
            # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            interest_over_time = pytrends.interest_over_time()
            related_queries = pytrends.related_queries()
            
            if interest_over_time.empty:
                logger.warning(f"âš ï¸ No Google Trends data for: {keyword}")
                return []
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            trends_data = []
            
            # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø¹Ø¨Ø± Ø§Ù„ÙˆÙ‚Øª
            if not interest_over_time.empty:
                latest_interest = interest_over_time[keyword].iloc[-1]
                trends_data.append({
                    'keyword': keyword,
                    'interest_score': int(latest_interest),
                    'trend_type': 'primary'
                })
            
            # Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©
            if related_queries[keyword]['rising'] is not None:
                rising_queries = related_queries[keyword]['rising'].head(3)
                for _, row in rising_queries.iterrows():
                    trends_data.append({
                        'keyword': row['query'],
                        'interest_score': int(row['value']) if row['value'] != '<1' else 1,
                        'trend_type': 'related'
                    })
            
            logger.info(f"âœ… Retrieved {len(trends_data)} real Google trends")
            return trends_data
            
        except ImportError:
            logger.error("âŒ pytrends not installed - install with: pip install pytrends")
            return []
        except Exception as e:
            logger.error(f"âŒ Google Trends API failed: {e}")
            return []
    
    def analyze_combined_trends(self, keyword):
        """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ - Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙÙ‚Ø·"""
        
        logger.info(f"ğŸ” Analyzing REAL trends for: {keyword}")
        
        try:
            google_trends = self.get_trending_keywords(keyword)
            
            if not google_trends:
                logger.warning(f"âš ï¸ No real data found for: {keyword}")
                return None
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
            total_interest = sum(t['interest_score'] for t in google_trends)
            viral_score = min(total_interest, 100)  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 100
            
            return {
                'keyword': keyword,
                'overall_viral_score': viral_score,
                'google_trends': google_trends,
                'reddit_trends': [],  # Ø³ÙŠØªÙ… Ù…Ù„Ø¤Ù‡Ø§ Ù…Ù† ViralScanner
                'recommendations': self._generate_real_recommendations(viral_score)
            }
            
        except Exception as e:
            logger.error(f"âŒ Combined analysis failed: {e}")
            return None
    
    def _generate_real_recommendations(self, viral_score):
        """ØªÙˆØµÙŠØ§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø·"""
        
        if viral_score >= 70:
            return [
                "ğŸ”¥ ØªØ±Ù†Ø¯ Ø³Ø§Ø®Ù† - Ø§Ø³ØªØºÙ„ Ø§Ù„ÙØ±ØµØ© ÙÙˆØ±Ø§Ù‹",
                "ğŸ“± Ø§Ù†Ø´Ø± Ù…Ø­ØªÙˆÙ‰ Ù…ØªØ¹Ù„Ù‚ Ø¨Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø¢Ù†",
                "ğŸ’° ÙÙƒØ± ÙÙŠ Ø§Ø³ØªØ«Ù…Ø§Ø± ØªØ³ÙˆÙŠÙ‚ÙŠ Ø³Ø±ÙŠØ¹"
            ]
        elif viral_score >= 40:
            return [
                "ğŸ“ˆ ØªØ±Ù†Ø¯ ØµØ§Ø¹Ø¯ - Ø±Ø§Ù‚Ø¨ Ø§Ù„ØªØ·ÙˆØ±Ø§Øª",
                "ğŸ’¡ Ø®Ø·Ø· Ù„Ù…Ø­ØªÙˆÙ‰ Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ Ù…ØªØ¹Ù„Ù‚",
                "â° Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ù…ØªÙˆØ³Ø·Ø© Ø§Ù„Ù…Ø¯Ù‰ Ù…Ù†Ø§Ø³Ø¨Ø©"
            ]
        else:
            return [
                "ğŸ“Š Ø§Ù‡ØªÙ…Ø§Ù… Ù…Ø­Ø¯ÙˆØ¯ Ø­Ø§Ù„ÙŠØ§Ù‹",
                "ğŸ” Ø§Ø¨Ø­Ø« Ø¹Ù† Ø²ÙˆØ§ÙŠØ§ Ø¬Ø¯ÙŠØ¯Ø©",
                "ğŸ“š Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ù‰"
            ]