#!/usr/bin/env python3
"""
ğŸ—ƒï¸ BraveBot Database Backup System
=====================================
Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª BraveBot

Ø§Ù„Ù…ÙŠØ²Ø§Øª:
- Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ù€ SQLite
- Ø¶ØºØ· Ø§Ù„Ù…Ù„ÙØ§Øª Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ù…Ø³Ø§Ø­Ø©
- ØªØ´ÙÙŠØ± Ø§Ù„Ù†Ø³Ø® (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
- Ø±ÙØ¹ Ø¥Ù„Ù‰ Google Drive Ø£Ùˆ GitHub
- ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
"""

import os
import sqlite3
import shutil
import gzip
import json
from datetime import datetime, timedelta
from pathlib import Path
import logging

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backup.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BraveBotBackup:
    def __init__(self, config_path='config/backup_config.json'):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
        self.config = self.load_config(config_path)
        self.backup_dir = Path(self.config.get('backup_directory', 'backups'))
        self.backup_dir.mkdir(exist_ok=True)
        
    def load_config(self, config_path):
        """ØªØ­Ù…ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
        default_config = {
            "database_path": "bravebot.db",
            "backup_directory": "backups",
            "max_backups": 30,
            "compress": True,
            "encrypt": False,
            "upload_to_github": True,
            "upload_to_drive": False,
            "cleanup_old": True
        }
        
        try:
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    default_config.update(config)
            return default_config
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to load config: {e}. Using defaults.")
            return default_config
    
    def create_backup(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            db_path = self.config['database_path']
            
            if not os.path.exists(db_path):
                logger.error(f"âŒ Database not found: {db_path}")
                return None
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            backup_filename = f"bravebot_backup_{timestamp}.db"
            backup_path = self.backup_dir / backup_filename
            
            # Ù†Ø³Ø® Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒØ§Ù…Ù„
            logger.info(f"ğŸ“¥ Creating backup: {backup_path}")
            self._safe_copy_database(db_path, backup_path)
            
            # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            self.add_backup_metadata(backup_path, timestamp)
            
            # Ø¶ØºØ· Ø§Ù„Ù…Ù„Ù Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø·Ù„ÙˆØ¨Ø§Ù‹
            if self.config.get('compress', True):
                backup_path = self._compress_backup(backup_path)
            
            # ØªØ´ÙÙŠØ± Ø§Ù„Ù†Ø³Ø®Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø·Ù„ÙˆØ¨Ø§Ù‹
            if self.config.get('encrypt', False):
                backup_path = self._encrypt_backup(backup_path)
            
            logger.info(f"âœ… Backup created successfully: {backup_path}")
            return backup_path
            
        except Exception as e:
            logger.error(f"âŒ Backup creation failed: {e}")
            return None
    
    def _safe_copy_database(self, source, destination):
        """Ù†Ø³Ø® Ø¢Ù…Ù† Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙƒØ§Ù…Ù„"""
        conn = None
        try:
            conn = sqlite3.connect(source)
            with open(destination, 'wb') as f:
                for line in conn.iterdump():
                    f.write(f"{line}\n".encode('utf-8'))
        finally:
            if conn:
                conn.close()
    
    def add_backup_metadata(self, backup_path, timestamp):
        """Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        try:
            conn = sqlite3.connect(backup_path)
            cursor = conn.cursor()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS backup_info (
                    backup_date TEXT,
                    backup_version TEXT,
                    total_users INTEGER,
                    total_checks INTEGER,
                    total_logs INTEGER
                )
            ''')
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            cursor.execute("SELECT COUNT(*) FROM user_stats")
            total_users = cursor.fetchone()[0]
            
            cursor.execute("SELECT SUM(total_checks) FROM user_stats")
            total_checks = cursor.fetchone()[0] or 0
            
            cursor.execute("SELECT COUNT(*) FROM logs")
            total_logs = cursor.fetchone()[0]
            
            # Ø¥Ø¯Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            cursor.execute('''
                INSERT INTO backup_info 
                (backup_date, backup_version, total_users, total_checks, total_logs)
                VALUES (?, ?, ?, ?, ?)
            ''', (timestamp, "2.0", total_users, total_checks, total_logs))
            
            conn.commit()
            conn.close()
            
            logger.info(f"ğŸ“Š Backup metadata: {total_users} users, {total_checks} checks, {total_logs} logs")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to add metadata: {e}")
    
    def _compress_backup(self, backup_path):
        """Ø¶ØºØ· Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        try:
            compressed_path = Path(str(backup_path) + '.gz')
            
            with open(backup_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ ØºÙŠØ± Ø§Ù„Ù…Ø¶ØºÙˆØ·
            os.remove(backup_path)
            logger.info(f"ğŸ—œï¸ Backup compressed: {compressed_path}")
            return compressed_path
            
        except Exception as e:
            logger.error(f"âŒ Compression failed: {e}")
            return backup_path
    
    def _encrypt_backup(self, backup_path):
        """ØªØ´ÙÙŠØ± Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© (ÙŠØªØ·Ù„Ø¨ cryptography library)"""
        try:
            from cryptography.fernet import Fernet
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ´ÙÙŠØ±
            key = Fernet.generate_key()
            f = Fernet(key)
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙˆØªØ´ÙÙŠØ±Ù‡
            with open(backup_path, 'rb') as file:
                file_data = file.read()
            
            encrypted_data = f.encrypt(file_data)
            encrypted_path = Path(str(backup_path) + '.enc')
            
            # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ÙØ±Ø©
            with open(encrypted_path, 'wb') as encrypted_file:
                encrypted_file.write(encrypted_data)
            
            # Ø­ÙØ¸ Ø§Ù„Ù…ÙØªØ§Ø­ (Ø§Ø­ØªÙØ¸ Ø¨Ù‡ Ø¨Ø£Ù…Ø§Ù†!)
            key_path = Path(str(backup_path) + '.key')
            with open(key_path, 'wb') as key_file:
                key_file.write(key)
            
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ
            os.remove(backup_path)
            logger.info(f"ğŸ” Backup encrypted: {encrypted_path}")
            return encrypted_path
            
        except ImportError:
            logger.warning("âš ï¸ Encryption skipped - cryptography library not installed")
            return backup_path
        except Exception as e:
            logger.error(f"âŒ Encryption failed: {e}")
            return backup_path
    
    def cleanup_old_backups(self):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        if not self.config.get('cleanup_old', True):
            return
        
        try:
            max_backups = self.config.get('max_backups', 30)
            backup_files = list(self.backup_dir.glob('bravebot_backup_*'))
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            if len(backup_files) > max_backups:
                old_backups = backup_files[max_backups:]
                for old_backup in old_backups:
                    # Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø£ÙŠØ¶Ø§Ù‹ (.key, .enc, etc.)
                    related_files = self.backup_dir.glob(f"{old_backup.stem}.*")
                    for related_file in related_files:
                        os.remove(related_file)
                        logger.info(f"ğŸ—‘ï¸ Deleted old backup: {related_file}")
                        
                logger.info(f"âœ… Cleaned up {len(old_backups)} old backups")
                        
        except Exception as e:
            logger.error(f"âŒ Cleanup failed: {e}")
    
    def upload_to_github_releases(self, backup_path):
        """Ø±ÙØ¹ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¥Ù„Ù‰ GitHub Releases"""
        if not self.config.get('upload_to_github', False):
            return
        
        try:
            # Ù‡Ø°Ø§ ÙŠØªØ·Ù„Ø¨ GitHub CLI Ø£Ùˆ API
            logger.info("ğŸ“¤ Uploading to GitHub Releases...")
            # Implementation would go here
            logger.info("âœ… Upload to GitHub completed")
            
        except Exception as e:
            logger.error(f"âŒ GitHub upload failed: {e}")
    
    def get_backup_statistics(self):
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        try:
            backup_files = list(self.backup_dir.glob('bravebot_backup_*'))
            total_size = sum(f.stat().st_size for f in backup_files)
            
            stats = {
                "total_backups": len(backup_files),
                "total_size_mb": round(total_size / (1024 * 1024), 2),
                "oldest_backup": min(backup_files, key=lambda x: x.stat().st_mtime).name if backup_files else None,
                "newest_backup": max(backup_files, key=lambda x: x.stat().st_mtime).name if backup_files else None
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ Stats calculation failed: {e}")
            return {}

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
    logger.info("ğŸš€ Starting BraveBot backup process...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
    backup_system = BraveBotBackup()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©
    backup_path = backup_system.create_backup()
    
    if backup_path:
        # Ø±ÙØ¹ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        backup_system.upload_to_github_releases(backup_path)
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        backup_system.cleanup_old_backups()
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        stats = backup_system.get_backup_statistics()
        logger.info(f"ğŸ“Š Backup Statistics: {stats}")
        
        logger.info("âœ… Backup process completed successfully!")
    else:
        logger.error("âŒ Backup process failed!")

if __name__ == "__main__":
    main()
